<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Capítulo 1X</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f9f9f9;
      margin: 0;
      padding: 2rem;
      max-width: 2000px;
      margin: auto;
    }
    h1 {
      color: #333;
      text-align: center;
    }
    p {
      line-height: 1.6;
      color: #444;
    }
    .volver {
      display: block;
      margin-top: 2rem;
      text-align: center;
    }
    .volver a {
      color: #0077cc;
      text-decoration: none;
      font-weight: bold;
    }
    .volver a:hover {
      color: #005999;
    }
  </style>
</head>
<body>
  <h1>Capítulo 1X</h1>

  <nav>
    <ul>
      <li><a href="#1X-1">15.1 Introducción</a></li>
      <li><a href="#1X-2">15.2</a></li>
      <li><a href="#1X-3">15.3</a></li>
      <li><a href="#1X-4">15.4</a></li>
      <li><a href="#1X-5">15.5</a></li>
      <li><a href="#1X-6">15.6</a></li>
      <li><a href="#1X-7">15.7</a></li>
      <li><a href="#1X-8">15.8</a></li>
      <li><a href="#1X-9">15.9</a></li>
      <li><a href="#1X-10">15.10</a></li>
    </ul>
  </nav> 

<section id="26-1">
  <h2>26.1 Introducción</h2>
  <p>Cuando analizamos el término <strong>virtualización</strong>, rápidamente se hace evidente que puede tener varios significados dependiendo del contexto y las tecnologías involucradas. En términos generales, la virtualización se refiere a sistemas o programas que se ejecutan sobre plataformas de software en lugar de directamente sobre el hardware físico del ordenador.</p>
  <p>En última instancia, todos estos sistemas utilizan recursos informáticos físicos, pero se pueden obtener varias ventajas al abstraer esos recursos del hardware físico. En este capítulo, aprenderás sobre conceptos de virtualización como máquinas virtuales y contenedores, componentes de las máquinas virtuales, cómo se implementan las máquinas virtuales y los contenedores, y los métodos utilizados para configurar máquinas virtuales.</p>
</section>
<hr>

<section id="26-2">
  <h2>26.2 Máquinas virtuales y contenedores</h2>
  <p>El primer tipo de sistema virtualizado es una <strong>máquina virtual</strong>, o VM. En este caso, se instala un sistema operativo completo sobre hardware virtual utilizando un <strong>hipervisor</strong> para gestionar los procesos. El hipervisor es un software que se instala sobre el hardware, como un servidor, creando una capa de virtualización y actuando como plataforma para crear máquinas virtuales. El hipervisor crea recursos virtuales como CPU, memoria, discos duros e interfaces de comunicación de E/S como puertos de red y puertos serie.</p>
  <p><em>Capas de máquina virtual:</em> De abajo hacia arriba: capa de hardware, capa de hipervisor, capa de VM que contiene hardware virtual y sistema operativo invitado, aplicaciones.</p>
  
  <div align="center">
    <img src="ch26_a.png" alt="" width="500" height="400" align="center">
    
  </div>
  
  <p>Existen dos métodos para instalar virtualización en un sistema informático. El primer método es instalar un <strong>hipervisor Tipo 1</strong>, también llamado hipervisor de metal desnudo, directamente sobre el hardware. El hipervisor Tipo 1 se sitúa directamente entre el hardware y la máquina virtual. El segundo método se llama <strong>virtualización alojada</strong>. Para configurar un sistema con virtualización alojada, se debe instalar un <strong>hipervisor Tipo 2</strong>, también llamado hipervisor alojado, sobre el sistema operativo existente (el sistema operativo anfitrión), en lugar de sobre el hardware como el hipervisor de metal desnudo.</p>
  <p><em>Comparación de hipervisores Tipo 1 y Tipo 2:</em> Gráfico izquierdo representa el hipervisor Tipo 1 (capa de hipervisor sobre capa de hardware). Gráfico derecho representa el hipervisor Tipo 2 (hipervisor sobre sistema operativo anfitrión).</p>
  
  <div align="center">
    <img src="ch26_b.png" alt="" width="500" height="400" align="center">
    
  </div>
  
  <p>El sistema operativo que se ejecuta en una VM se llama <strong>sistema operativo invitado</strong>. Este sistema operativo suele instalarse como una imagen preconfigurada, pero también puede construirse desde fuentes de instalación como CD, DVD o PXE, para realizar las tareas necesarias. Esta configuración, junto con la instalación de software de aplicación, parches de seguridad y configuración de red, la realiza un administrador de sistemas como si se tratara de una máquina física en un centro de datos. Por supuesto, al ser virtual, la VM puede estar compartiendo hardware con otras VM, e incluso estar ubicada físicamente en otro continente, más cerca de los clientes que se conectarán a ella.</p>
  <h4>Considere esto</h4>
  <p>Uno de los principales beneficios de la virtualización es que hace más eficientes los recursos informáticos. Tradicionalmente, el hardware solo podía ejecutar un sistema informático a la vez, lo cual no era un problema para usuarios individuales; sin embargo, con el crecimiento de la tecnología digital y la necesidad creciente de conectividad y datos, los centros de datos comenzaron a adoptar la virtualización como solución para ofrecer recursos informáticos de forma eficiente.</p>
  <p>Una evolución de la virtualización es la <strong>tecnología de contenedores</strong>, que está siendo adoptada rápidamente por organizaciones de desarrollo de software. Los <strong>contenedores Linux</strong> permiten a los diseñadores de sistemas evitar los sistemas operativos tradicionales y acceder a los recursos informáticos de forma diferente. Una aplicación en contenedor depende de un motor de contenedores para comunicarse con el sistema operativo anfitrión sin necesidad de un hipervisor ni una VM invitada. Cuando los programadores diseñan estas aplicaciones, incluyen todas las dependencias necesarias para realizar una tarea específica dentro del contenedor. Además, normalmente se construyen varios contenedores que se comunican entre sí para realizar tareas que antes se hacían con un solo programa ejecutándose sobre un sistema operativo.</p>

  <div align="center">
    <img src="ch26_c.png" alt="" width="500" height="400" align="center">
    
  </div>

  <p><em>Capas de contenedor:</em> De abajo hacia arriba: capa de hardware, capa de sistema operativo anfitrión, motor Docker, aplicaciones.</p>
  <p>Esto ofrece varias ventajas, incluyendo el uso de menos recursos, ciclos de lanzamiento más cortos y la abstracción de elementos del programa respecto al sistema operativo anfitrión para mejorar la portabilidad. Recientemente, ha surgido la arquitectura de contenedores híbrida. Esta consiste en un enfoque multinivel donde un hipervisor, ejecutándose sobre hardware físico, soporta máquinas virtuales que, a su vez, alojan contenedores.</p>
  <p>Las organizaciones están evaluando los pros y contras de las distintas configuraciones disponibles hoy en día. Entre los <strong>pros</strong> se incluyen: los contenedores usan menos recursos físicos que las VM, ofrecen mayor fiabilidad y escalabilidad, requieren menos almacenamiento debido a su naturaleza ligera y ofrecen ventajas de rendimiento tanto en tiempo de arranque como en rendimiento de aplicaciones.</p>
  <p>Entre los <strong>contras</strong>, cuando los contenedores se ejecutan directamente sobre el hardware, puede requerirse un esfuerzo considerable para garantizar la segregación y mantener la seguridad. Al ejecutarse sobre recursos compartidos, el motor de contenedores debe ajustarse para evitar interferencias entre y dentro de los contenedores. También debe controlar el acceso a recursos como memoria, dispositivos de E/S y conexiones de red. Finalmente, cuando se permite a los programadores crear estos pequeños recursos independientes, es fácil que su número se descontrole. Las ventajas de la contenerización pueden verse superadas por el tiempo y esfuerzo necesarios para gestionarlos y mantenerlos si no se aplica disciplina desde el principio. Afortunadamente, la comunidad de código abierto ha adoptado el desarrollo de contenedores y las herramientas para diseñarlos, desplegarlos y mantenerlos siguen creciendo rápidamente.</p>
</section>
<hr>

<section id="26-3">
  <h2>26.3 Opciones de virtualización</h2>
  <p>Cuando se trata de máquinas virtuales, existen muchos proveedores y proyectos de código abierto entre los que elegir. Se debe considerar cuidadosamente antes de decidirse por una tecnología de VM en particular, ya que la compatibilidad entre ellas es difícil en el mejor de los casos, y cambiar de una a otra requiere un esfuerzo considerable. Las máquinas virtuales suelen desplegarse a partir de una imagen que contiene el sistema operativo invitado, programas de aplicación y cualquier personalización que el administrador haya configurado para la gestión del sistema. Estas imágenes pueden desplegarse de forma semiautomática, aunque pueden requerir intervención humana para configurar la red y la seguridad.</p>

  <h3>VMware</h3>
  <p>Una de las plataformas más antiguas y ampliamente desplegadas es <strong>VMware</strong>, propiedad de Dell Technologies. VMware desarrolla y mantiene una amplia gama de tecnologías de virtualización, además de proporcionar asistencia técnica a sus clientes. Sus plataformas vSphere y ESXi son casi omnipresentes en industrias donde se valora la estabilidad y el soporte.</p>

  <h3>KVM</h3>
  <p><strong>KVM</strong>, o Máquina Virtual basada en Kernel, es un hipervisor de código abierto integrado en Linux. No debe confundirse con un conmutador KVM (teclado, vídeo, ratón), que es un dispositivo de hardware que permite compartir un monitor entre varios ordenadores. Como programa de código abierto, tiene la ventaja de no ser propietario y no requerir licencias. Su despliegue está muy extendido y generalmente se considera más escalable que VMware. KVM se utiliza ampliamente en la distribución SUSE Linux Enterprise.</p>

  <h3>Xen</h3>
  <p>El proyecto <strong>Xen</strong> es otro hipervisor de código abierto. Se considera un sistema Tipo 1 o de metal desnudo porque se ejecuta directamente sobre el hardware sin un sistema operativo anfitrión. Esto, junto con su diseño de microkernel, permite un rendimiento muy alto en un sistema ligero. Aunque Xen se usa con mayor frecuencia en Linux, no está vinculado a ningún sistema operativo específico. Actualmente, Xen es el único hipervisor de metal desnudo ofrecido como software de código abierto y es un proyecto colaborativo de la Linux Foundation.</p>

  <h3>Hyper-V</h3>
  <p><strong>Hyper-V</strong> es un producto de virtualización de hardware ofrecido por Microsoft. Es popular en entornos que ya ejecutan servidores y equipos de escritorio con Windows. Aunque parece un hipervisor Tipo 2 (alojado) que se ejecuta sobre Windows Server, en realidad se instala por debajo de cualquier software Windows u otro sistema operativo. También permite instalar distribuciones Linux compatibles en un entorno Windows.</p>

  <h3>VirtualBox</h3>
  <p><strong>VirtualBox</strong> es un producto de código abierto popular de Oracle que es relativamente fácil de instalar y configurar. Es un hipervisor Tipo 2 que se ejecuta en sistemas anfitriones Windows, Macintosh y Linux. Se describe como un “virtualizador de propósito general para hardware x86”. Aunque puede ejecutarse en entornos de servidor, está más orientado a usuarios de escritorio que necesitan ejecutar distintos sistemas operativos ocasionalmente.</p>

  <h3>Docker</h3>
  <p>Como se mencionó anteriormente, los contenedores Linux se están convirtiendo rápidamente en el modelo estándar de la industria para el desarrollo de aplicaciones en red. Las dos fuerzas dominantes en el movimiento de contenerización son <strong>Docker</strong> y <strong>Kubernetes</strong>.</p>
  <p><strong>Docker</strong> es el motor de contenedores que permite a los programadores e ingenieros de sistemas crear aplicaciones contenerizadas. Estas aplicaciones son componentes independientes que no dependen de ningún sistema operativo anfitrión para funcionar. Su entorno de ejecución, <code>containerd</code>, facilita el empaquetado del código de la aplicación y sus dependencias en un contenedor que puede ejecutarse de forma consistente en distintas infraestructuras, permitiendo que las aplicaciones funcionen independientemente de la infraestructura subyacente. Como proyecto de código abierto de alto nivel de la Cloud Native Computing Foundation, <code>containerd</code> se mejora constantemente para satisfacer las necesidades de la industria.</p>

  <h3>Kubernetes</h3>
  <p><strong>Kubernetes</strong>, desarrollado originalmente por Google, fue convertido en un proyecto de código abierto en 2014. Kubernetes puede describirse como una plataforma que “proporciona un entorno de gestión centrado en contenedores” para contenedores, microservicios e infraestructura en la nube. Proporciona etiquetas y anotaciones para ayudar a los usuarios a rastrear recursos. “Orquesta” recursos de computación, red y almacenamiento para aplicaciones y flujos de trabajo en contenedores. También está altamente integrado con Docker, por lo que ambos programas pueden trabajar juntos.</p>
  <p>Kubernetes está organizado en <strong>clusters</strong>, <strong>nodos</strong> (anteriormente llamados minions), <strong>pods</strong> y <strong>contenedores</strong>. El nodo maestro se encarga de mantener el estado deseado en el cluster. Proporciona comunicación con las APIs, inicia y detiene procesos, y balancea cargas de trabajo.</p>
  <p><em>Estructura de Kubernetes:</em> De izquierda a derecha: nodo maestro, flechas apuntando a nodos más pequeños que contienen Docker y Pods, con contenedores dentro.</p>

  <div align="center">
    <img src="ch26_d.png" alt="" width="500" height="400" align="center">
    
  </div>

</section>
<hr>

<section id="26-4">
  <h2>26.4 IaaS</h2>
  <p>Colectivamente, los elementos que hemos estado discutiendo son la base de <strong>IaaS</strong> (Infraestructura como Servicio). IaaS es una forma de <strong>computación en la nube</strong>, que consiste en la entrega de recursos informáticos compartidos bajo demanda (software y/o datos) a organizaciones y usuarios a través de internet.</p>
  <p><em>Computación en la nube:</em> Una figura de nube etiquetada como "Infraestructura en la nube" contiene recursos informáticos virtuales (por ejemplo, cómputo, red, almacenamiento, aplicaciones) con líneas que se extienden desde la nube hacia dispositivos de usuario (por ejemplo, escritorio, portátil, móvil).</p>
  <p>La computación en la nube es un tema popular de discusión, y tanto organizaciones como individuos muestran gran interés en las ventajas que puede ofrecer. Tan pronto como fue posible que los sistemas informáticos crearan y gestionaran otros sistemas mediante virtualización y automatización, los programadores y diseñadores de sistemas se inclinaron hacia sistemas y redes definidos por software. Como resultado, las organizaciones ven cada vez más la nube como esencial para sus negocios y operaciones.</p>

  <div align="center">
    <img src="ch26_e.png" alt="" width="500" height="400" align="center">
    
  </div>

  <h4>Considere esto</h4>
  <p>A menudo se escucha que algo está “en la nube”, pero ¿qué significa eso? Físicamente, una nube puede describirse como recursos informáticos ubicados en uno o varios centros de datos remotos que pueden ser accedidos a través de internet.</p>
  <p>Al abstraer las máquinas gestionadas del hardware físico, se vuelve posible y deseable construir sistemas en software tanto como sea posible. Al colocar instancias de máquinas virtuales sobre hardware gestionado por hipervisores y conectarlas mediante redes definidas por software, no solo se redujeron las demandas físicas, sino que se aumentó la velocidad, ya que cada parte del sistema solo necesita comunicarse dentro de las APIs (interfaces de programación de aplicaciones) de una tecnología de orquestación. Sistemas de orquestación como <strong>OpenStack</strong>, <strong>Apache CloudStack</strong> y <strong>OpenNebula</strong> han hecho posible la computación en la nube.</p>
  <p>Estos sistemas han podido avanzar rápidamente gracias al desarrollo de software de código abierto, que permite que diferentes empresas —a menudo competidoras— trabajen juntas para crear estándares comunes y bases de código compartidas. Cada uno de estos proyectos se divide en subproyectos más pequeños, que pueden ser desarrollados por equipos especializados en áreas técnicas específicas. Al colaborar y compartir mejoras en el código, han logrado construir sistemas robustos y adaptables a muchas necesidades distintas.</p>
  <p>Las máquinas virtuales Linux tienen la capacidad de comunicarse con contenedores Linux, grupos de almacenamiento en bloque, conmutadores y enrutadores de red virtuales, almacenes de bases de datos y todos los demás componentes que antes formaban parte de un programa monolítico o del diseño de un centro de datos. En última instancia, al crear hipervisores que ejecutan máquinas virtuales Linux, los programadores y arquitectos de sistemas actuales han creado colaborativamente nuestro mundo moderno en línea en mucho menos tiempo y con muchos menos recursos de los que cualquier empresa individual podría haber logrado.</p>
</section>
<hr>

<section id="26-5">
  <h2>26.5 Configuración de máquinas virtuales y contenedores</h2>
  <p>Cuando se crea una nueva máquina virtual o contenedor, debe poder conectarse al mundo exterior. Como cualquier otro recurso en una red, necesitará un nombre de host único, una dirección IP, una máscara de subred adecuada, DNS y una ruta predeterminada. Dado que es deseable que las imágenes y contenedores sean creados y gestionados por otros programas, se requieren scripts de inicialización para realizar cambios en una imagen base.</p>
  <p>La imagen, que se almacena como un conjunto de archivos listos para usar, carecerá de información importante como la configuración de red correcta, usuarios, grupos y permisos, rutas a recursos como bases de datos y bloques de almacenamiento, claves SSH y cualquier otra configuración que normalmente haría un administrador del sistema de forma manual. Estos scripts deben ser flexibles y accesibles por otros programas para minimizar la intervención humana, y también deben ser seguros, ya que pueden contener información sensible como credenciales de acceso.</p>
  <p>Afortunadamente, existen utilidades como <code>cloud-init</code> y los scripts <code>kickstart</code> (para VMs) que ayudan a simplificar este proceso. Estas utilidades pueden invocar otros programas mediante una API, leer metadatos desde un servidor o configurar instancias. En Kubernetes, incluso existen contenedores especializados llamados <strong>Init containers</strong> que se ejecutan antes de que inicien los contenedores de aplicación.</p>
  <p><strong>SSH</strong>, o <em>secure shell</em>, se utiliza para comunicarse y gestionar tanto máquinas virtuales como contenedores. Cuando se crea una nueva VM o contenedor desde una imagen, el administrador puede usar una utilidad como <code>cloud-init</code> para generar nuevas claves de host SSH. El par de claves es un conjunto de números aleatorios relacionados matemáticamente, generados por un algoritmo, que se utiliza para autenticar a un usuario (que también podría ser otro sistema). Los administradores también pueden generar pares de claves manualmente con el comando <code>ssh-keygen</code>. Las claves SSH incorrectas o ausentes suelen ser la razón por la que los sistemas no se comunican entre sí, incluso cuando las direcciones IP y los nombres de host son correctos.</p>
  <p>Otro factor que debe gestionarse es el identificador único del sistema, o <strong>uuid</strong>. Este uuid debe generarse y añadirse al archivo de configuración <code>D-Bus machine ID</code> durante la instalación o al primer arranque de la VM o contenedor. El comando <code>dbus-uuidgen</code> puede utilizarse para generar o leer un ID único universal para un sistema. Este ID tiene la forma de un número de 128 bits que es único, o al menos muy poco probable que se repita hasta el año 3400 d.C. El uuid debe permanecer sin cambios hasta que el sistema se reinicie, para que los procesos sepan en qué kernel se están ejecutando. Además, el uuid puede utilizarse para identificar cualquier objeto en un despliegue en la nube y es comúnmente usado por bases de datos SQL y lenguajes de programación como JavaScript y Python para identificar objetos.</p>
  <p>La utilidad <code>cloud-init</code> puede utilizarse para automatizar parámetros de configuración inicial en una máquina virtual Linux. Además de establecer el nombre de host, claves SSH y configuración de red, también puede establecer la contraseña de root, zona horaria, puntos de montaje e invocar scripts personalizados que proporcionen configuraciones adicionales no soportadas por los ajustes de <code>cloud-init</code>.</p>
  <p>Otros ajustes críticos que deben verificarse para asegurar que productos virtualizados como VMs y contenedores funcionen correctamente son las <strong>extensiones de virtualización</strong>, que son soporte de hardware para virtualización integrado en la CPU, como las extensiones <strong>VT-x</strong> de Intel y <strong>AMD-V</strong> de AMD. Estos ajustes pueden verificarse en el sistema anfitrión en el archivo <code>/proc/cpuinfo</code> y en la BIOS del sistema. Por ejemplo, los <em>flags</em> en el archivo <code>/proc/cpuinfo</code> pueden usarse para determinar si las extensiones VT-x de Intel y AMD-V están instaladas:</p>
  <pre><code>sysadmin@localhost:~$ cat /proc/cpuinfo
Output Omitted...
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca
cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdt scp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 popcnt aes lahf_lm tpr_shadow vnmi flexpriority ept vpid dtherm ida arat</code></pre>
  <p>En la salida anterior, el flag <code>lm</code> indica que el sistema tiene una CPU de 64 bits y el flag <code>vmx</code> indica que la extensión de virtualización VT-x de Intel está habilitada en la BIOS.</p>

  <h4>Considere esto</h4>
  <p>Para entender por qué se necesita la virtualización, es útil una breve explicación de la arquitectura de CPU.</p>
  <p>Existen dos tipos principales de arquitectura de CPU: <strong>x86</strong> y <strong>x64</strong>. La arquitectura x86 tiene sus raíces en los procesadores de 8 bits construidos por Intel a finales de los años 70. A medida que mejoraron las capacidades de fabricación y aumentaron las demandas de software, Intel extendió la arquitectura de 8 bits a 16 bits, y más tarde, en 1985, a 32 bits. El procesador actual de 32 bits es lo que se conoce como x86. En 2003, AMD introdujo una extensión de 64 bits a la arquitectura x86 y, posteriormente, en 2004, Intel anunció su propia extensión de arquitectura de 64 bits. El procesador actual de 64 bits se conoce como x64. Comprender la diferencia entre 32 y 64 bits es importante porque la tecnología de virtualización es compatible con 64 bits, pero no con 32 bits.</p>
  <p>Para verificar qué tipo de CPU está utilizando tu sistema Linux, ejecuta el comando <code>lscpu</code>:</p>
  <pre><code>sysadmin@localhost:~$ lscpu
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Output Omitted...</code></pre>
  <p>Finalmente, algunas plataformas de virtualización requieren que el sistema operativo invitado sea compatible con controladores específicos, llamados <strong>controladores invitados</strong> o <strong>agentes invitados</strong>, que no están incluidos en sus distribuciones estándar. Estos controladores proporcionan funcionalidades y rendimiento adicionales como soporte para el ratón, compartir carpetas entre el anfitrión y la VM, configuración de inicio de sesión automático y sincronización de hora, entre otros. Estos controladores son necesarios porque la forma en que un hipervisor se comunica con el hardware físico es diferente de cómo lo haría normalmente el sistema operativo.</p>
</section>
<hr>

  

  <hr>
  <div class="volver">
    <a href="../index.html">← Volver al índice</a>
  </div>

</body>
</html>
